BEGIN:VCALENDAR
VERSION:2.0
PRODID:Data::ICal 0.20
X-LIC-LOCATION:America/Los_Angeles
X-WR-CALNAME:UW CSE Colloquium Calendar
X-WR-TIMEZONE:America/Los_Angeles
BEGIN:VEVENT
DESCRIPTION:TBD
DTEND:20160301T163000
DTSTART:20160301T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium:  TBD (TBD): TBD
UID:20160301T153000a@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2846
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:I will present flexible algorithms for model discovery and model fitting which apply to broad\, open-ended classes of models\, yet which also incorporate model-specific algorithmic insights. First\, I will introduce a framework for building probabilistic models compositionally out of common modeling motifs\, such as clustering\, sparsity\, and dimensionality reduction. This compositional framework yields a variety of existing models as special cases. We can flexibly perform posterior inference across this large\, open-ended space of models by composing sophisticated inference algorithms carefully designed for the individual modeling motifs. An automatic structure search procedure over this space of models yields sensible analyses of datasets as diverse as motion capture\, natural image patches\, and Senate voting records\, all using a single software package with no hand-tuned metaparameters. Applying a similar compositional structure search procedure to Gaussian Process models yields interpretable decompositions of diverse time series datasets and enables automatic generation of natural language reports.  Finally\, compositional structure search depends crucially on the estimation of intractable likelihoods. I will briefly outline an approach for obtaining precise likelihood estimates with rigorous tail bounds by sandwiching the true value between stochastic upper and lower bounds.\n\nBio\nRoger Grosse is a Postdoctoral Fellow in the University of Toronto machine learning group. He received his Ph.D. in computer science from MIT under the supervision of of Bill Freeman. He is a recipient of the NDSEG Graduate Fellowship\, the Banting Postdoctoral Fellowship\, and outstanding paper awards at the International Conference of Machine Learning (ICML) and the Conference for Uncertainty in AI (UAI). He is also a co-creator of Metacademy\, an open-source web site for developing personalized learning plans in machine learning and related fields.
DTEND:20160303T163000
DTSTART:20160303T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Roger B Grosse (MIT/University of Toronto): Exploiting compositionality to explore a large space of model structures
UID:20160303T153000c@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2850
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:This talk will be taped for internal UW CSE faculty use only.  It will not be available for on-demand viewing.\n  \nFrequent headline-grabbing data breaches suggest that current best practices for safeguarding personal data are woefully inadequate.  To try to move beyond the cycle of attacks and patches we see today\, I design and build systems with formal end-to-end guarantees.  For example\, to provide strong guarantees for outsourced computations\, I developed a new cryptographic framework\, verifiable computation\, which allows clients to outsource general computations to completely untrusted services and efficiently verify the correctness of each returned result.  Through improvements to the theory and the underlying systems\, we reduced the costs of verification by over twenty orders of magnitude.  As a result\, verifiable computation is now a thriving research area that has produced several startups\, as well as enhancements to the security and privacy of X.509\, MapReduce\, and Bitcoin.\n\nWhile verifiable computation provides strong guarantees\, even the best cryptographic system is useless if implemented badly\, applied incorrectly\, or used in a vulnerable system.  Thus\, I have led a team of researchers and engineers in the Ironclad project\, working to expand formal software verification to provide end-to-end guarantees about the security and reliability of complex systems.  By creating a set of new tools and methodologies\, Ironclad produced the first complete stack of verified-secure software.  We also recently developed the first methodology for verifying both the safety and liveness of complex distributed systems implementations.  While interesting challenges remain\, I expect that verification will fundamentally improve the software that underpins our digital and physical infrastructure.\n\nBio\nBryan Parno is a Researcher in the Security and Privacy Group at Microsoft Research.  After receiving a Bachelor's degree from Harvard College\, he completed his PhD at Carnegie Mellon University\, where his dissertation won the 2010 ACM Doctoral Dissertation Award.  In 2011\, he was selected for Forbes' 30-Under-30 Science List.  He formalized and worked to optimize verifiable computation\, receiving a Best Paper Award at the IEEE Symposium on Security and Privacy his advances.  He coauthored a book on Bootstrapping Trust in Modern Computers\, and his work in that area has been incorporated into the latest security enhancements in Intel CPUs. His research into security for new application models was incorporated into Windows and received a Best Paper Awards at the IEEE Symposium on Security and Privacy and the USENIX Symposium on Networked Systems Design and Implementation.  He has recently extended his interest in bootstrapping trust to the problem of building practical\, formally verified secure systems. His other research interests include user authentication\, secure network protocols\, and security in constrained environments (e.g.\, RFID tags\, sensor networks\, or vehicles).
DTEND:20160310T163000
DTSTART:20160310T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Bryan Parno (Microsoft Research): Fully Verified Outsourced Computation
UID:20160310T153000d@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2844
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:NOTE: This talk will be taped only for internal UW CSE faculty use - it will not be broadcast live and it won't be available for viewing on-demand.\n  \nDatacenter workloads have demanding performance requirements\, including the simultaneous need for high throughput\, low tail latency\, and high server utilization. While modern hardware is compatible with these goals\, modern operating systems remain a bottleneck. Better OS abstractions could significantly improve performance\, yet deploying these abstractions has become intractable given the size and complexity of today's systems.\n  \nI will first discuss Dune\, a kernel extension that allows OS developers to sidestep software and hardware complexity by running an OS within an ordinary Linux process.  With Dune\, developers can both access the capabilities of raw hardware and fall back on the functionality of a full Linux environment where convenient. I will then discuss IX and Shinjuku\, two generations of new datacenter-focused operating systems that were enabled by Dune. IX provides a novel system call interface that greatly improves network throughput without sacrificing latency. For example\, IX improves Memcached's TCP throughput by 5x over Linux. Shinjuku\, an ongoing research effort\, aims to significantly increase CPU utilization through a centralized approach to intra-server load balancing.\n  \nBio: \nAdam Belay is a Ph.D. candidate in Computer Science at Stanford University\, where he is a member of the Secure Computer Systems Group and the Multiscale Architecture and Systems Team. Previously\, he worked on storage virtualization at VMware Inc. and contributed substantial power management code to the Linux Kernel project.  Adam's research area is operating systems and networking.  Much\nof his work has focused on restructuring computer systems so that developers can more easily reach the full performance potential of hardware. Adam has received a Stanford Graduate Fellowship\, a VMware Graduate Fellowship\, and an OSDI Jay Lepreau Best Paper Award.
DTEND:20160329T163000
DTSTART:20160329T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Adam Matthew Belay (Stanford University): Unleashing Hardware Potential through Better OS Abstractions
UID:20160329T153000b@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2855
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:NOTE: This talk will NOT be broadcast live!  It will be taped only for internal UW CSE faculty use.\n\nFuture visual computing applications -- from photorealistic real-time rendering\, to 4D light field cameras\, to pervasive sensing and computer vision-demand orders of magnitude more computation than we currently have. From data centers to mobile devices\, performance and energy scaling is limited by locality (the distance over which data has to move\, e.g.\, from nearby caches\, far away main memory\, or across networks) and parallelism. Because of this\, I argue that we should think of the performance and efficiency of an application as determined not just by the algorithm and the hardware on which it runs\, but critically also by the organization of computations and data. For algorithms with the same complexity -- even the exact same set of arithmetic operations and data executing on the same hardware\, the order and granularity of execution and placement of data can easily change performance by an order of magnitude because of locality and parallelism. To extract the full potential of our machines\, we must treat the organization of computation as a first class concern while working across all levels from algorithms and data structures\, to compilers\, to hardware.\n\nThis talk will present facets of this philosophy in systems I have built for visual computing applications from image processing and vision\, to 3D rendering\, simulation\, optimization\, and 3D printing. I will show that\, for data-parallel pipelines common in graphics\, imaging\, and other data-intensive applications\, the organization of computations and data for a given algorithm is constrained by a fundamental tension between parallelism\, locality\, and redundant computation of shared values. I will focus particularly on the Halide language and compiler for image processing\, which explicitly separates what computations define an algorithm from the choices of organization which determine parallelism\, locality\, memory footprint\, and synchronization. I will show how this approach can enable much simpler programs to deliver performance often many times faster than the best prior hand-tuned C\, assembly\, and CUDA implementations\, while scaling across radically different architectures\, from ARM cores\, to massively parallel GPUs\, to FPGAs and custom ASICs.\n\nBio\n\nJonathan Ragan-Kelley is a postdoc in computer science at Stanford. He works on high-efficiency visual computing\, including systems\, compilers\, and architectures for image processing\, vision\, 3D rendering\, 3D printing\, physical simulation\, and scientific computing. He earned his PhD in Computer Science at MIT in 2014\, where he built the Halide language for high-performance image processing. Halide is now used throughout industry to deploy code to hundreds of millions of smartphones and process tens of billions of images per day. Jonathan previously built the Lightspeed preview system\, which was used on over a dozen films at Industrial Light & Magic and was a finalist for an Academy Technical Achievement Award. He has worked in GPU architecture\, compilers\, and research at NVIDIA\, Intel\, and ATI.
DTEND:20160331T163000
DTSTART:20160331T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Jonathan Ragan-Kelley (MIT/Stanford): Organizing Computation for High-Performance Visual Computing
UID:20160331T153000c@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2858
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:TBD
DTEND:20160404T163000
DTSTART:20160404T153000
LOCATION:Gates Commons\, CSE 691 Paul G Allen Center for Computer Science & Engineering
SUMMARY:CSE Research Seminar:  TBD (TBD): TBD
UID:20160404T153000@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2879
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:The recent success of machine learning (ML) in both science and industry has generated an increasing demand to support ML algorithms at scale. In this talk\, I will discuss strategies to gracefully scale machine learning on modern parallel computational platforms. A common approach to such scaling is coordination-free parallel algorithms\, where individual processors run independently without communication\, thus maximizing the time they compute. However\, analyzing the performance of these algorithms can be challenging\, as they often introduce race conditions and synchronization problems.\n\nIn this talk\, I will introduce a general methodology for analyzing asynchronous parallel algorithms. The key idea is to model the effects of core asynchrony as noise in the algorithmic input.  This allows us to understand the performance of several popular asynchronous machine learning approaches\, and to determine when asynchrony effects might overwhelm them.  To overcome these effects\, I will propose a new framework for parallelizing ML algorithms\, where all memory conflicts and race conditions can be completely avoided. I will discuss the implementation of these ideas in practice\, and demonstrate that they outperform the state-of-the-art across a large number of ML tasks on gigabyte-scale data sets.\n\nBio\nDimitris Papailiopoulos is a postdoctoral researcher in the Department of Electrical Engineering and Computer Sciences at UC Berkeley and a member of the AMPLab. His research interests span machine learning\, coding theory\, and parallel and distributed algorithms\, with a current focus on coordination-free parallel machine learning\, large-scale data and graph analytics\, and the use of codes to speed up distributed computation. Dimitris completed his Ph.D. in electrical and computer engineering at UT Austin in 2014. At Austin he worked under the supervision of Alex Dimakis. In 2015\, he received the IEEE Signal Processing Society\, Young Author Best Paper Award.
DTEND:20160405T163000
DTSTART:20160405T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Dimitris Papailiopoulos (University of Texas\, Austin/UC Berkeley): Less Talking\, More Learning: Avoiding Coordination In Parallel Machine Learning Algorithms
UID:20160405T153000c@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2860
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:The purpose of obfuscation is to recompile programs in a way that preserves their functionality but otherwise renders their code unintelligible. Envisioned by Diffie and Hellman already in the 70's as a means of obtaining public-key encryption\, it is known by now that this concept may have far reaching implications to cryptography and complexity theory. In particular\, program obfuscation suggests (often exclusive) solutions to some of the most challenging privacy and security problems in the age of cloud computing and social networks.\n\nAt the same time\, program obfuscation has turned out to be  an evasive goal to achieve\, or to even meaningfully define. For a long time\, solutions have been confined to heuristics\, whereas attempts to achieve any sense of provable security have mostly led to impossibility results. This gloomy state dramatically changed in recent years\, when it was shown that a relatively weak notion called indistinguishability obfuscation may be within reach (so far\, based on strong computational assumptions) and still has the potential of realizing many dream applications.\n\nIn this talk\, I will review the different aspects of obfuscation\, including central notions\, limitations\, and feasibility. As a demonstration of the power of obfuscation\, I will present a recent implication [Bitansky-Paneth-Rosen\, FOCS15] that goes beyond cryptography into a fundamental problem in complexity and algorithmic game theory -- the hardness of finding a Nash equilibrium. I will conclude with the main open problems and challenges in the area of obfuscation.\n\nBio\nNir Bitansky is a postdoctoral associate at the cryptography group at MIT CSAIL. He earned his Ph.D. in computer science from Tel Aviv University in 2014. His research is centered around cryptography and its interplay with other areas of theoretical computer science.
DTEND:20160407T163000
DTSTART:20160407T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Nir Bitansky (Tel Aviv University/MIT): Program obfuscation: the power of unreadable code
UID:20160407T153000b@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2865
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:Convex optimization has been studied extensively and is a prominent tool in various areas such as combinatorial optimization\, data analysis\, operations research\, and scientific computing.  Each field has developed specialized tools including data structures\, sampling methods\, and dimension reduction. In the past several years\, I have been combining and improving the optimization techniques from different fields to design faster optimization algorithms. \n  \nIn this talk\, I will discuss my work in this direction and illustrate it through my results on linear programming and general convex optimization. In particular\, I will present a new algorithm for solving linear programs\, which gives the first improvement to the running time for linear programming in 25 years. Then\, I will present the first nearly cubic time algorithm for solving general convex optimization problems. Furthermore\, I will discuss how these two results can be used to improve the running time of many classical combinatorial problems such as maximum flow and submodular function minimization.\n  \nThis talk will assume no prior knowledge of optimization.\n  \nBio: \nYin Tat Lee is a Ph.D. candidate in the department of mathematics at the Massachusetts Institute of Technology. He is interested in designing faster algorithms\, particularly for problems in optimization. Since he began his Ph.D. in 2012\, he has combined ideas from continuous and discrete mathematics to substantially advance the state-of-the-art for solving many fundamental problems in computer science\, such as linear programming\, maximum flow\, and submodular function minimization. He has received a variety of awards\, including the Best Student Paper Award at FOCS 2015\, Best Paper Award at SODA 2014\, Best Paper Award and Best Student Paper Award at FOCS 2014\, and Notable Article in Computing in 2014 by Computing Reviews.
DTEND:20160412T163000
DTSTART:20160412T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Yin Tat Lee (MIT): Faster algorithms for fundamental convex problems and their applications in combinatorial optimization
UID:20160412T153000b@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2856
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:The goal of my research is to develop algorithmic and theoretical techniques that push highly agile robotic systems to the brink of their hardware limits while guaranteeing that they operate in a safe manner despite uncertainty in the environment and dynamics.\n  \nIn this talk\, I will describe my work on algorithms for the synthesis of feedback controllers that come with associated formal guarantees on the stability of the robot and show how these controllers and certificates of stability can be used for robust planning in environments previously unseen by the system. In order to make these results possible\, my work connects deeply to computational tools such as sums-of-squares (SOS) programming and semidefinite programming from the theory of mathematical optimization\, along with approaches from nonlinear control theory.\n  \nI will describe this work in the context of the problem of high-speed unmanned aerial vehicle (UAV) flight through cluttered environments previously unseen by the robot. In this context\, the tools I have developed allow us to guarantee that the robot will fly through its environment in a collision-free manner despite uncertainty in the dynamics (e.g.\, wind gusts or modeling errors). The resulting hardware demonstrations on a fixed-wing airplane constitute one of the first examples of provably safe and robust control for robotic systems with complex nonlinear dynamics that need to plan in realtime in environments with complex geometric constraints.\n  \nBio: \nAnirudha Majumdar is a Ph.D. candidate in the Electrical Engineering and Computer Science department at MIT. He is a member of the Robot Locomotion Group at the Computer Science and Artificial Intelligence Lab and is advised by Prof. Russ Tedrake. Ani received his undergraduate degree in Mechanical Engineering and Mathematics from the University of Pennsylvania\, where he was a member of the GRASP lab. His research is primarily in robotics: he works on algorithms for controlling highly dynamics robots such as unmanned aerial vehicles with formal guarantees on the safety of the system. Ani's research has been recognized by the Siebel Foundation Scholarship and the Best Conference Paper Award at the International Conference on Robotics and Automation (ICRA) 2013.\n
DTEND:20160414T163000
DTSTART:20160414T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Anirudha Majumdar (MIT): Control of agile robots in complex environments with formal safety guarantees
UID:20160414T153000a@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2874
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:At present\, user interfaces are typically created by designers for an idealized set of users and the most common interactive devices. In view of the growing number and diversity of new devices\, it becomes increasingly difficult to design for the many possible input/output characteristics and contexts of use\, and interfaces remain fairly limited in their ability to adapt to devices and their role in a user's larger task. In this talk\, I will describe how my research in human-computer interaction blurs the boundaries of interactive technologies and enables user interfaces to seamlessly grow\, with the help of users and crowds\, to take advantage of many devices and use contexts that are poorly supported by current design. For example\, W3Touch allows user interfaces to adapt to a large variety of touch devices based on user performance metrics and crowd data mining\; XDBrowser customizes existing single-device web interfaces for multi-device use based on user-defined cross-device design patterns\; and WearWrite allows a user to provide input and interact with a document using their smartwatch on one end of the interface\, and a crowd of writers to perform actions on the user's behalf using larger and more powerful devices on the other end of the interface. I will outline a research agenda that has the goal of making user interface design itself natural\, embedding human intelligence into interactive computing technologies\, and supporting evidence-based design using large-scale interaction data.\n  \nBio: \nMichael Nebeling is a Swiss NSF Advanced Postdoc.Mobility Fellow and a Visiting Researcher in the Human-Computer Interaction Institute at Carnegie Mellon University hosted by Anind Dey. Before coming to CMU in 2015\, he was a Senior Researcher and Lecturer at the Department of Computer Science at ETH Zurich\, where he obtained his PhD in 2012. His research interests are at the intersection of human-computer interaction\, user interface engineering\, ubiquitous computing\, and crowdsourcing. As part of his research\, he has created many systems to support the design and evaluation of rich\, context-aware and adaptive\, cross-device\, multi-touch and multi-modal gesture and speech interfaces\, and has received six Best Paper Awards and Honorable Mentions at premier venues in human-computer interaction and engineering\, including ACM CHI and ACM EICS. Michael is committed to promoting engineering research within the HCI community. He has been an Associate Chair for the CHI Technology\, Systems and Engineering subcommittee for CHI 2014-2016. He was EICS 2015 Papers co-chair and EICS 2014 Late-Breaking Results co-chair. He is on the EICS steering committee and also a Senior PC member for EICS 2016.\n
DTEND:20160419T163000
DTSTART:20160419T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Michael Nebeling (ETH Zurich/CMU): Multiple Devices + Crowds = Richer User Interfaces
UID:20160419T153000a@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2863
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:Improvements in the performance and energy consumption of general purpose processors have slowed dramatically over the last decade.  This is due to the combined effect of breakdowns in transistor scaling\, causing severe chip-level power limitations\, and monolithic and inefficient general purpose microarchitecture.\n  \nIn this work\, I propose and evaluate a concept called "behavioral specialization"\, where the design of general purpose processors is modularized by adding programmable offload engines\, each best-suited for different program behaviors or characteristics.  To explore this principle\, I designed a modular general-purpose core which transparently improves performance and energy efficiency by integer factors. I also extend these principles to create an architecture for highly-regular and parallelizable workloads for a further order of magnitude improvements.\n  \nI have discovered that a small number of exploitable program behaviors can cover a majority of applications\, that dataflow architectures become practical and useful in hybrid execution with a general purpose core\, and that programmable architectures can be competitive with domain specific alternatives on well-behaved workloads\, with only small area and negligible energy overheads.  Overall\, behavioral specialization causes disruptive change in microprocessor tradeoffs\, enabling mobile-class processor energy-efficiency with desktop-class performance.\n  \nBio: \nTony Nowatzki is a Ph.D. student in the Department of Computer Sciences at the University of Wisconsin-Madison advised by Karu Sankaralingam. His broad research interests include architecture and compiler codesign and mathematical modeling. He is recipient of a Google PhD Fellowship. His work has been recognized with a IEEE Micro Top Picks award\, a PLDI Distinguished Paper Award\, SIGARCH and SIGPLAN CACM Research Highlights nominations\, and an IEEE Best of CAL award. He was the lead author on a Synthesis Lecture on "Optimization and Mathematical Modeling in Computer Architecture."\n
DTEND:20160421T163000
DTSTART:20160421T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Tony Nowatzki (U Wisconsin\, Madison): Reviving General Purpose Computing with Architectural Specialization
UID:20160421T153000b@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2875
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:NOTE: This talk will not be broadcast live.  It will be taped only for internal CSE faculty use.\n\nTBD
DTEND:20160426T163000
DTSTART:20160426T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Julia Rubin (University of Toronto/MIT): TBD
UID:20160426T153000a@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2862
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:When real people interact with algorithms (e.g. in auctions\, crowdsourcing\, Bitcoin\, etc.)\, they impose additional objectives beyond simply that the algorithm is correct\, fast\, and uses little storage. People strategize during these interactions\, so algorithms deployed in these settings must be robust against potential manipulation. Additionally\, people prefer transparent interactions\, so these algorithms must also be as simple as possible. My research addresses these\, and other novel challenges that arise when algorithms interact with strategic agents.\n  \nIn this talk\, I will focus on one aspect of this agenda and present a new algorithmic framework to solve any optimization problem in a way that is robust to strategic manipulation. I will further apply this framework to extend Myerson's celebrated characterization of optimal single-item auctions to multiple items (Myerson 1981)\, design mechanisms for job scheduling (Nisan and Ronen 1999)\, and resolve other problems at the interface of algorithms and game theory.\n  \nFinally\, I will briefly show how strategic considerations motivate nice questions in "traditional" areas of algorithm design as well\, and present some of my work in online algorithms\, convex optimization\, and parallel algorithms.  \n  \nBio: \nMatt received his PhD in EECS from MIT in 2014\, where he was advised by Costis Daskalakis. He is now a postdoc at Princeton University in the Computer Science department. His research focuses on designing algorithms that address constraints imposed by the strategic nature of agents that interact with them. For his thesis work on these topics\, he received MIT's George M. Sprowls award and the SIGecom Doctoral Dissertation award. Matt received his B.A. in Math from Cornell University.
DTEND:20160428T163000
DTSTART:20160428T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Matt Weinberg (MIT/Princeton): Algorithms for Strategic Agents
UID:20160428T153000c@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2876
END:VEVENT
END:VCALENDAR

