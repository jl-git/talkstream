BEGIN:VCALENDAR
VERSION:2.0
PRODID:Data::ICal 0.20
X-LIC-LOCATION:America/Los_Angeles
X-WR-CALNAME:UW CSE Colloquium Calendar
X-WR-TIMEZONE:America/Los_Angeles
BEGIN:VEVENT
DESCRIPTION:Surveys reveal that network outages are prevalent\, and that ma
 ny outages take hours to resolve\, resulting in significant lost revenue. 
 Many bugs are caused by errors in configuration files which are programmed
  using arcane\, low-level languages\, akin to machine code. Taking our cue
  from program and hardware verification\, we suggest fresh approaches.\nI 
 will first describe a geometric model of network forwarding called Header 
 Space. While header space analysis is similar to finite state machine veri
 fication\, we exploit domain-specific structure to scale better than off-t
 he shelf model checkers.   Next\, I show how to exploit physical symmetry 
 to scale network verification for large data centers. While Emerson and Si
 stla showed how to exploit symmetry for model checking in 1996\, they expl
 oited symmetry on the logical Kripke structure.\n \nWhile the first part o
 f the talk is about analysis\, I will then describe our work in synthesis.
    I will set the stage by describing a new re-configurable router archite
 cture we proposed called RMT. This has led to an emerging language for pro
 gramming routers called P4 that promises to extend the boundaries of Softw
 are Designed Networks. I will then describe a synthesis problem for flexib
 le routers\, akin to code generation (packet transactions) and new algorit
 hmic questions related to synthesizing routes in the face of uncertainty.\
 n(With collaborators at Edinburgh\, MSR\, MIT\,Stanford\, and University o
 f Washington.)\n  \nBIOGRAPHY\nGeorge Varghese received his Ph.D. in 1992 
 from MIT. From 1993-1999\, he was a professor at Washington University\, a
 nd at UCSD from 1999 to 2013. He was the Distinguished Visitor in the comp
 uter science department at Stanford University from 2010-2011. He joined M
 icrosoft Research in 2012.\n  \nHis book "Network Algorithmics" was publis
 hed in December 2004 by Morgan-Kaufman. In May 2004\, he co-founded NetSif
 t\, which was acquired by Cisco Systems in 2005. With colleagues\, he has 
 won best paper awards at SIGCOMM (2014)\, ANCS (2013)\, OSDI (2008)\, PODC
  (1996)\, and the IETF Applied Networking Prize (2013). He has won lifetim
 e achievement awards in networking from the EE community (2014 Kobayashi A
 ward) and the CS Community (2014 SIGCOMM Award).  He won the IIT Bombay Di
 stinguished Alumni Award in 2015. 
DTEND:20160105T163000
DTSTART:20160105T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: George Varghese (Microsoft Research): Network Ve
 rification and Synthesis - When Hoare Meets Cerf 
UID:20160105T153000a@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2832
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:NOTE: Talk was live-broadcast only - no archive available!\n  \
 nThe ultimate goal of cancer biology is to enable the use of molecular pro
 files\, such as DNA\, RNA\, protein and epigenetic data\, of individual ca
 ncer patients for diagnosis and treatment. There is substantial need for b
 etter ways to choose chemotherapy drugs in individual cancer patients. For
  example\, patients over 65 with acute myeloid leukemia (AML)\, an aggress
 ive blood cancer\, have no better prognosis today than they did in 1980. F
 or a growing number of diseases\, there is a fair amount of data on molecu
 lar profiles from patients. The most important step necessary to realize t
 he ultimate goal is to identify molecular markers (e.g.\, certain genes or
  mutations) in these molecular data that predict treatment outcomes\, such
  as response to each chemotherapy drug. However\, due to the high-dimensio
 nality (i.e.\, the number of variables is much greater than the number of 
 samples) along with potential biological or experimental confounders\, it 
 is an open challenge to identify robust biomarkers that are replicated acr
 oss different studies.\n  \nIn this talk\, I will present two distinct mac
 hine learning (ML) approaches to resolve this challenge. These methods lea
 rn the low-dimensional features that are likely to represent important mol
 ecular events in the disease process in an unsupervised fashion\, based on
  molecular profiles from multiple populations of cancer patients. I will p
 resent two applications of these two methods  -- AML\, and ovarian cancer.
  When the first method was applied to AML data in collaboration with UW Ce
 nter for Cancer Innovation\, a novel molecular marker for topoisomerase in
 hibitors\, widely used chemotherapy drugs in AML treatment\, was revealed.
   The other method applied to ovarian cancer data led to a potential molec
 ular driver for an aggressive 'mesenchymal' subtype\, in collaboration wit
 h UW Pathology and UW Genome Sciences. These findings will lead to better 
 ways to treat cancer.\n  \nThis research is funded by the American Cancer 
 Society\, the National Science Foundation\, and the National Institutes of
  Health.\n  \nBio: \nProfessor Su-In Lee is an Assistant Professor in the 
 Departments of Computer Science & Engineering and Genome Sciences at the U
 niversity of Washington. She received her Ph.D. degree in Electrical Engin
 eering from Stanford University in 2009. Before joining the UW in 2010\, s
 he was a Visiting Assistant Professor in the Computational Biology Departm
 ent at Carnegie Mellon University.\n  \nHer interest is in developing adva
 nced machine learning (ML) algorithms to solve various important problems 
 in biology and medicine. Her lab is currently funded by the American Cance
 r Society\, the National Institutes of Health\, the National Science Found
 ation\, the Institute of Translational Health Sciences and the Solid Tumor
  Translational Research.  \n 
DTEND:20160112T163000
DTSTART:20160112T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Su-In Lee (Assistant Professor joint with UW CSE
  and UW Genome Science): Big data approach to identify novel biomarkers in
  cancer
UID:20160112T153000a@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2793
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:Despite all of the recent progress in Natural Language Processi
 ng\, humans still have much to teach machines about language.  By combinin
 g the complementary strengths of human language aptitude with sheer comput
 ational horsepower\, we can learn important phenomena in a way that is sen
 sitive to the cost of human expertise.  We focus our cooperative attention
  on the problem of annotating text corpora with the true (i.e.\, high qual
 ity) labels\, both for the benefit of supervised learning in NLP and to fa
 cilitate linguistic investigation.\n  \nIt is now common practice to reduc
 e the cost of producing annotated corpora by crowdsourcing multiple redund
 ant judgments and aggregating them -- for example\, using majority vote --
  to produce good consensus labels. We improve the quality of consensus lab
 els inferred from imperfect annotations in a number of ways.  First\, we s
 how that\, contrary to popular preference\, generative annotation aggregat
 ion models tend to outperform conditional aggregation models.  We leverage
  this insight to develop CSLDA\, a novel annotation aggregation model that
  improves on the state of the art for a variety of annotation tasks.  Seco
 nd\, for situations when data is not readily modeled generatively\, we int
 roduce a conditional data modeling approach -- based on vector-space text 
 representations -- that achieves state-of-the-art results on several unusu
 al semantic annotation tasks.  Finally\, we introduce a family of models c
 apable of aggregating heterogeneous annotations such as label frequencies 
 and labeled features.  Continuing with the theme of human/machine cooperat
 ion\, we present a multi-annotator active learning algorithm for this mode
 l family that jointly selects an annotator\, data items\, and annotation t
 ype.\n   \nThis is joint work with Paul Felt (now at IBM)\, Kevin Seppi (B
 YU)\, Jordan Boyd-Graber (Colorado)\, Kevin Black (now at Xactware)\, and 
 Robbie Haertel (now at Google).\n   \nBio:\nEric Ringger is a Research Sci
 entist at Facebook in Seattle.  He is also an associate professor of compu
 ter science at Brigham Young University\, currently on leave.  His researc
 h passion is to facilitate human/machine cooperation to solve difficult le
 arning and natural language problems\, such as revealing useful patterns i
 n natural language data.  His research has contributed to NLP\, machine le
 arning\, text mining\, and (most recently) search.\n
DTEND:20160119T163000
DTSTART:20160119T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Eric Ringger (Facebook): Humans and Machines Coo
 perating to Find the "Truth" about Language: Bayesian Methods for Annotati
 on Aggregation
UID:20160119T153000a@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2819
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:It has been nearly four years since the first MOOCs (massive op
 en online courses) were offered by Stanford University. MOOCs are now offe
 red to tens of millions of learners worldwide\, by hundreds of top univers
 ities. MOOCs are no longer an experiment - the learning\, reach\, and valu
 e they offer are now a reality. I will show how MOOCs provide opportunitie
 s for open-ended projects\, intercultural learner interactions\, and colla
 borative learning. I will discuss some of data that we are collecting from
  MOOCs\, and what we are learning from these data about both courses and l
 earners. I'll also describe data and examples regarding the kind of transf
 ormative impact that can be derived from providing millions of people with
  access to the world's best education.\n\nBio\nDaphne Koller is the Presid
 ent and Co-Founder of Coursera\, the largest open online education provide
 r with more than 15 million registered learners worldwide. Daphne leads th
 e growth and nurturing of Coursera's partnerships with over 130 universiti
 es and educational institutions. Previously\, she was the Rajeev Motwani P
 rofessor of Computer Science at Stanford University\, where she served on 
 the faculty for 18 years. She is the author of over 180 refereed publicati
 ons appearing in venues such as Science\, Cell\, and Nature Genetics. Daph
 ne was recognized as one of TIME Magazine 's 100 most influential people i
 n 2012 and Newsweek's 10 most important people in 2010. She has been honor
 ed with multiple awards and fellowships during her career including the Sl
 oan Foundation Faculty Fellowship in 1996\, the ONR Young Investigator Awa
 rd in 1998\, the IJCAI Computers and Thought Award in 2001\, and the MacAr
 thur Foundation Fellowship in 2004. Daphne was inducted into the National 
 Academy of Engineering in 2011 and elected a fellow of the American Academ
 y of Arts and Sciences in 2014.
DTEND:20160121T163000
DTSTART:20160121T153000
LOCATION:EEB-105
SUMMARY:Ben Taskar Memorial Lecture: Daphne Koller (Coursera): MOOCs Turn 4
 : What Have We Learned?
UID:20160121T153000b@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2818
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:Advancements in semiconductor technology have brought smart mic
 ro-scale wireless sensors within reach for many applications. However\, po
 wer continues to be a critical obstacle\, as these devices must typically 
 operate without a wired power connection for long periods.  Innovative ult
 ra-low-power analog\, mixed-signal\, and RF circuit design is necessary to
  realize the promise of micro-scale ubiquitous wireless sensors. \n  \nIn 
 this talk I will describe low-power circuits that address challenges at ea
 ch stage in the signal chain of a wireless sensor: signal acquisition\, pr
 ocessing\, and communication. These will include efficient low-noise ampli
 fiers for neural recording\, sensing of sub-picoampere currents\, and a lo
 w-power wireless transmitter.  At the signal processing stage\, I will des
 cribe our recent work in mixed-signal computation for machine learning\, i
 ncluding an analog deep machine learning engine that exhibits a 280x impro
 vement in energy efficiency relative to an equivalent digital implementati
 on. I will also discuss higher-level considerations relevant to selecting 
 a computational strategy and broad design themes that have emerged through
 out the course of this work.\n  \nBio: \nJeremy Holleman is an Associate P
 rofessor in the department of Electrical Engineering and Computer Science 
 at the University of Tennessee\, Knoxville.  He received a Bachelor's degr
 ee in Electrical Engineering from Georgia Tech in 1997\, and the Master's 
 and Ph.D. degrees in Electrical Engineering in 2006 and 2009\, both from t
 he University of Washington.  He has previously worked for Data I/O and Na
 tional Semiconductor. His research interests include low-power analog VLSI
 \, biomedical interfaces\, mixed-mode signal processing\, and neuromorphic
  engineering.
DTEND:20160128T163000
DTSTART:20160128T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Jeremy Holleman (University of Tennessee): Smart
  Silicon: Low-power Circuits for Intelligent Wireless Sensors
UID:20160128T153000c@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2843
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:Biomedical research is generating a huge amount of genomic data
 . Extracting knowledge from Big Data to guide novel biological discovery i
 s critical to fully realize its potential. However\, high-dimensional geno
 mic data is known for its heterogeneity and noise.  One important way to e
 nrich for true signal is to examine its effects in different but complemen
 tary data types (e.g.\, mRNA expression\, histone modification\, and metab
 olite abundance). In this talk\, I will present my work on integrating mul
 tiple types of data to study how cellular metabolic\, transcriptional and 
 epigenetic states interact in stem cell biology. First I will present a co
 mputational method that integrates gene expression\, metabolite abundance 
 and flux\, and network topology to infer genome-scale cell type-specific m
 etabolic networks. Then I will present a case study where the integration 
 of gene expression and metabolite abundance data leads to the discovery of
  a metabolic enzyme controlling the level of repressive histone modificati
 ons\, which in turn regulate a set of genes critical for early human devel
 opment. I will also present a new approach to identify genes that regulate
  lineage-specific differentiation by integrating gene expression and histo
 ne modification ChIP-seq data. In the future\, leveraging large genomic da
 tasets from the ENCODE project\, NIH Roadmap Epigenomics project and the F
 ANTOM5 project\, cell type-specific metabolic networks will be reconstruct
 ed as a framework to understand how developmental transcription factors af
 fect metabolism\, the pattern of epigenetic modifications in the metabolic
  network\, and critical nodes in the metabolic network that affect epigene
 tic status. \n  \nBio: \nYuliang Wang is a Senior Research Associate in th
 e Computational Biology Program\, School of Medicine at Oregon Health & Sc
 ience University. He received his PhD in Chemical Engineering and MS in Ap
 plied Statistics from University of Illinois\, Urbana-Champaign in 2013. H
 e did his postdoctoral training in computational biology at Sage Bionetwor
 ks in Seattle (2013-2014).\n\n
DTEND:20160201T110000
DTSTART:20160201T100000
LOCATION:Gates Commons\, 691 Paul G Allen Center for Computer Science & Eng
 ineering
SUMMARY:CSE Research Seminar: Yuliang Wang (UIUC/OHSU): Integrative genomic
  data analysis to understand interactions between metabolic\, transcriptio
 nal\, epigenetic states in stem cell biology
UID:20160201T100000c@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2853
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:Cities are increasingly publishing data about their operations 
 while also internally using data to improve the effectiveness and quality 
 of services through optimization\, predictive analytics\, and other method
 s.  This represents new opportunities for collaboration between cities\, n
 ational laboratories\, and universities in areas ranging from scalable dat
 a infrastructure to tools for data analytics\, along with challenges such 
 as replicability of solutions between cities\, integrating and validating 
 data for scientific investigation\, and protecting privacy.  For many urba
 n questions\, new data sources will be required with greater spatial and/o
 r temporal resolution\, driving innovation in the use of sensor in mobile 
 devices as well as embedded sensing infrastructure in the built environmen
 t.  Catlett will discuss the work that Argonne National Laboratory and the
  University of Chicago are doing in partnership with the City of Chicago a
 nd other cities through the Urban Center for Computation and Data\, focusi
 ng on key scalable data infrastructure\, data analytics\, and resilient au
 tonomous urban-scale sensor networks.\n  \nBio: \nCharlie Catlett is a Sen
 ior Computer Scientist at Argonne National Laboratory and a Senior Fellow 
 at the Computation Institute of the University of Chicago and Argonne\, wh
 ere he is founding director of the Urban Center for Computation and Data (
 UrbanCCD). He is also a Visiting Artist at the School of the Art Institute
  of Chicago.  Catlett is working with scientists from area universities an
 d laboratories\, members of the technical community in the Chicago area an
 d city policymakers to explore science-based approaches to opportunities a
 nd challenges of city design and operation.  \n  \nFrom 2007 to 2011 Catle
 tt was the Chief Information Officer at Argonne\, and from 2004 to 2007 he
  was Director of the National Science Foundation's TeraGrid initiative - a
  nationally distributed supercomputing facility involving fifteen universi
 ties and federal laboratories. Before joining the UChicago and Argonne in 
 2000\, Catlett was Chief Technology Officer at the National Center for Sup
 ercomputing Applications at the University of Illinois at Urbana-Champaign
 .  At NCSA he participated\, beginning at NCSA's founding in 1985\, in the
  development of NSFNET\, one of several early national networks that evolv
 ed into what we now experience as the Internet. Following the release of N
 CSA's Mosaic web browser\, he and his team at NCSA helped develop and supp
 ort scalable web server infrastructure.\n  \nFrom 1999 to 2004 Catlett dir
 ected the design and deployment of the I-WIRE optical network\, funded by 
 the State of Illinois\, which connects research institutions in the Chicag
 o area and downstate Illinois with a dedicated fiber optic network for res
 earch and education.   Catlett received a B.S. in Computer Engineering fro
 m the University of Illinois\, Urbana-Champaign in 1983.
DTEND:20160202T163000
DTSTART:20160202T153000
LOCATION:
SUMMARY:UW CSE Colloquium: Charlie  Catlett (Argonne National Laboratory an
 d the University of Chicago): The Array of Things: Resilient\, Autonomous\
 , Urban-Scale Sensor Networks
UID:20160202T153000c@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2829
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:In robot collectives\, interactions between large numbers of in
 dividually simple robots lead to complex global behaviors. A great source 
 of inspiration is social insects such as ants and bees\, where thousands o
 f individuals coordinate to handle advanced tasks like food supply and nes
 t construction in a remarkably scalable and error tolerant manner. Likewis
 e\, robot swarms have the ability to address tasks beyond the reach of sin
 gle robots\, and promise more efficient parallel operation and greater rob
 ustness due to redundancy. Key challenges involve both control and physica
 l implementation. In this seminar I will discuss an approach to such syste
 ms relying on embodied intelligent robots designed as an integral part of 
 their environment\, where passive mechanical features replace the need for
  complicated sensors and control.\n   The majority of my talk will focus o
 n a team of robots for autonomous construction of user-specified three-dim
 ensional structures developed during my thesis. Additionally\, I will give
  a brief overview of my research on the Namibian mound-building termites t
 hat inspired the robots. Finally\, I will talk about my current research t
 hrust\, enabling stand-alone centimeter-scale soft robots to eventually be
  used in swarm robotics as well. My work advances the aim of collective ro
 botic systems that achieve human-specified goals\, using biologically-insp
 ired principles for robustness and scalability.\n  \nShort Bio:  \nKirstin
  Petersen is a Postdoc with the Physical Intelligence Department at the Ma
 x Planck Institute for Intelligent Systems in Germany. Here\, she develops
  novel soft actuators to enable stand-alone centimeter-scale soft robots. 
 Kirstin finished her Ph.D. in computer science at Harvard University and t
 he Wyss Institute for Biologically Inspired Engineering in 2014\, her thes
 is topic a combination of termite-inspired robots for collective construct
 ion and corresponding studies of the real termites. This work was featured
  in and on the cover of Science in February 2014\, and was elected among t
 he top ten scientific breakthroughs of 2014. Kirstin completed her M.Sc. i
 n modern artificial intelligence in 2008 and a B.Sc. in electro-technical 
 engineering in 2005\, both with the University of Southern Denmark. In her
  spare time Kirstin is an avid hiker and traveler.
DTEND:20160209T163000
DTSTART:20160209T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Kirstin H Petersen (Harvard University/Max Planc
 k Institute for Intelligent Systems): Designing Robot Collectives
UID:20160209T153000a@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2864
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:Most applications of machine learning across science and indust
 ry rely on the holdout method for model selection and validation. Unfortun
 ately\, the holdout method often fails in the now common scenario where th
 e analyst works interactively with the data\, iteratively choosing which m
 ethods to use by probing the same holdout data many times.\n  \nIn this ta
 lk\, we apply the principle of algorithmic stability to design reusable ho
 ldout methods\, which can be used many times without losing the guarantees
  of fresh data. Applications include a model benchmarking tool that detect
 s and prevents overfitting at scale.\n  \nWe conclude with a bird's eye vi
 ew of what algorithmic stability says about machine learning at large\, in
 cluding new insights into stochastic gradient descent\, the most popular o
 ptimization method in contemporary machine learning.\n  \nShort bio: \nMor
 itz Hardt is a senior research scientist at Google Research. After obtaini
 ng a PhD in computer science from Princeton University in 2011\, he worked
  at IBM Research Almaden on algorithmic principles of machine learning. Th
 en he moved to Google to join the Foundations of Applied Machine Learning 
 group where his mission is to build guiding theory and scalable algorithms
  that make the practice of machine learning more reliable\, transparent\, 
 and effective.\n
DTEND:20160211T163000
DTSTART:20160211T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Moritz Hardt (Princeton/Google Research): Overco
 ming Overfitting with Algorithmic Stability
UID:20160211T153000c@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2848
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:Moore's Law has historically been the driving force behind comp
 uting industry innovation. Today\, the computing industry as a whole is fa
 cing several challenges on all the key frontiers of microprocessor innovat
 ion and development. Generational improvements in processor performance\, 
 continual reductions in its power consumption\, and sustained hardware exe
 cution reliability have all but reached a plateau\, if not begun to falter
 \, due to technology scaling issues. These challenges affect all domains o
 f computing\, ranging from mobile devices to high-performance systems. Thi
 s talk focuses specifically on end-user mobile computing devices\, outlini
 ng the challenges that face us in building future high-performance mobile 
 devices that are responsive on a mobile power budget. By examining the mob
 ile application software stack and the existing processor architectures th
 at support it\, the talk presents how to bridge the increasing gap between
  end-user satisfaction and energy-efficient mobile computing. Domain-speci
 fic architectures\, coupled with feedback-directed runtime software optimi
 zation that is guided by programmer-driven annotations\, can enable us to 
 build future high-performance\, energy-efficient mobile computing devices.
  Synergistic\, and systematic\, cross-layer optimization is a fundamental 
 necessity for overcoming the performance\, power and reliability challenge
 s that mark the "end" of the Moore's Law era and the beginning of the Moor
 e's crawl period.\n  \nBiography: \nVijay Janapa Reddi is an Assistant Pro
 fessor in the Department of Electrical and Computer Engineering at The Uni
 versity of Texas at Austin. His research interests include system architec
 ture and software design and implementation to address performance\, power
 \, energy and reliability issues for mobile and high-performance computing
  systems. He is the recipient of the Intel Early Career Award\, PLDI Most 
 Influential Paper Award\, and Best Paper and Top Picks awards in Computer 
 Architecture. Beyond his research activities\, Vijay is very passionate ab
 out STEM education\, particularly involving computer science education sta
 rting at an early age. He is responsible for the Hands-On Computer Science
  (HaCS) curriculum that teaches computer science to middle school students
  in the Austin Independent School District (AISD) through Arduino-based ha
 nds-on projects. AISD ties directly into the heart of the public education
  system in Austin\, Texas. Vijay received his Ph.D. in Computer Science fr
 om Harvard University. He can be contacted at vj@ece.utexas.edu.\n
DTEND:20160218T163000
DTSTART:20160218T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Vijay Janapa Reddi (Harvard University/UT Austin
 ): From Moore's Law to Moore's Crawl: Architecting the Next Generation of 
 Mobile Computing Devices
UID:20160218T153000a@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2847
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:NOTE: This talk will NOT be broadcast live.  It will be taped o
 nly for internal use.\n  \nWe introduce a new kernel-based approach for th
 e design of multi-layer convolutional feature representations for signals 
 and images. The majority of deep convolutional neural networks (ConvNets) 
 require supervision to learn state-of-the-art feature representations\, wh
 ich can be problematic for real-world applications where supervision can b
 e expensive or unconceivable. Unsupervised learning of feature representat
 ions is currently a major open problem. \n  \nThe proposed approach allow 
 to define a feature representation that is based on a kernel (feature) map
 . The exact version of this feature representation is data-independent. An
  explicit kernel (feature) map can be computed to approximate it for compu
 tational efficiency\, without the need for supervision. We illustrate the 
 potential of the approach on several applications: i) patch matching\; ii)
  image retrieval\; iii) image classification. We settle new state-of-the-a
 rt\, or compete on par with state-of-the-art methods\, on public benchmark
 s for all three computer vision tasks. \n  \nBio: \nZaid Harchaoui is curr
 ently Visiting Assistant Professor at the Courant Institute for Mathematic
 al Sciences of NYU. Zaid was a permanent researcher at Inria from 2010 to 
 2015. He received his PhD from ParisTech (Paris\, France). He received the
  Inria award for scientific excellence and the NIPS reviewer award. He gav
 e a tutorial on "Frank-Wolfe\, greedy algorithms\, and friends" at ICML'14
 \, on "Large-scale visual recognition" at CVPR'13\, and on "Machine Learni
 ng for Computer Vision" at MLSS Kyoto 2015. He recently co-organized the w
 orkshop on “Optimization for Machine Learning” at NIPS'14\, and the "O
 ptimization and Statistical Learning" workshop in 2015 and 2013 in Ecole d
 e Physique des Houches (France). He is associate editor of IEEE Signal Pro
 cessing Letters. He is Area Chair for ICML 2015\, ICML 2016\, and NIPS 201
 6.  
DTEND:20160223T163000
DTSTART:20160223T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Zaid Harchaoui (Telecom Paris Tech/New York Univ
 ersity): Towards Deep Convolutional Methods without Supervision
UID:20160223T153000a@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2859
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:Even though considered a rapid prototyping tool\, 3D printers a
 re very slow. Many objects require several hours of printing time or even 
 have to print overnight. One could argue that the way 3D printers are curr
 ently operated is similar to the batch processing of punched cards in the 
 early days of computing: all input parameters are pre-defined in the 3D mo
 deling stage\, the 3D printer then simply executes the instructions withou
 t human intervention. Since batch processing requires carefully thinking a
 head\, it is limited to expert users who can reason about the consequences
  of their design decisions.\n\nIn the history of computing\, moving away f
 rom batch processing enabled completely new interaction paradigms: while b
 atch processing required carefully thinking ahead\, command line input all
 owed for tighter feedback loops\, and direct manipulation finally enabled 
 even novice users to quickly iterate towards a solution. I believe repeati
 ng this evolution for the editing of physical matter will enable novice us
 ers to build objects only trained experts can create today.\n\nIn this tal
 k\, I show how technological advances in two areas lay the foundation for 
 achieving this goal: First\, we need to develop tools that allow novice us
 ers to directly manipulate physical matter under computer control. Second\
 , since direct manipulation requires feedback in real-time after every edi
 ting step\, we need faster fabrication techniques that can accomplish inst
 ant physical change.\n\nBio\nStefanie Mueller is a PhD student working wit
 h Patrick Baudisch in the Human-Computer Interaction Lab at Hasso Plattner
  Institute. In her research\, she develops novel hardware and software sys
 tems that advance personal fabrication technologies. Stefanie has publishe
 d 10 papers at the most selective HCI venues CHI and UIST\, for which she 
 received a best paper award and two best paper nominees. She is also servi
 ng on the CHI and UIST program committees as an associate chair. In additi
 on\, Stefanie has been an invited speaker at universities and research lab
 s\, such as MIT\, CMU\, Cornell\, Microsoft Research\, Disney Research\, a
 nd Adobe Research.\n
DTEND:20160225T163000
DTSTART:20160225T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Stefanie Mueller (Hasso Plattner Institute): Int
 eracting with Personal Fabrication Machines
UID:20160225T153000c@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2845
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:TBD
DTEND:20160301T163000
DTSTART:20160301T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium:  TBD (TBD): TBD
UID:20160301T153000a@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2846
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:TBD
DTEND:20160303T163000
DTSTART:20160303T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Roger B Grosse (MIT/University of Toronto): TBD
UID:20160303T153000a@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2850
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:Frequent headline-grabbing data breaches suggest that current b
 est practices for safeguarding personal data are woefully inadequate.  To 
 try to move beyond the cycle of attacks and patches we see today\, I desig
 n and build systems with formal end-to-end guarantees.  For example\, to p
 rovide strong guarantees for outsourced computations\, I developed a new c
 ryptographic framework\, verifiable computation\, which allows clients to 
 outsource general computations to completely untrusted services and effici
 ently verify the correctness of each returned result.  Through improvement
 s to the theory and the underlying systems\, we reduced the costs of verif
 ication by over twenty orders of magnitude.  As a result\, verifiable comp
 utation is now a thriving research area that has produced several startups
 \, as well as enhancements to the security and privacy of X.509\, MapReduc
 e\, and Bitcoin.\n\nWhile verifiable computation provides strong guarantee
 s\, even the best cryptographic system is useless if implemented badly\, a
 pplied incorrectly\, or used in a vulnerable system.  Thus\, I have led a 
 team of researchers and engineers in the Ironclad project\, working to exp
 and formal software verification to provide end-to-end guarantees about th
 e security and reliability of complex systems.  By creating a set of new t
 ools and methodologies\, Ironclad produced the first complete stack of ver
 ified-secure software.  We also recently developed the first methodology f
 or verifying both the safety and liveness of complex distributed systems i
 mplementations.  While interesting challenges remain\, I expect that verif
 ication will fundamentally improve the software that underpins our digital
  and physical infrastructure.\n\nBio\nBryan Parno is a Researcher in the S
 ecurity and Privacy Group at Microsoft Research.  After receiving a Bachel
 or's degree from Harvard College\, he completed his PhD at Carnegie Mellon
  University\, where his dissertation won the 2010 ACM Doctoral Dissertatio
 n Award.  In 2011\, he was selected for Forbes' 30-Under-30 Science List. 
  He formalized and worked to optimize verifiable computation\, receiving a
  Best Paper Award at the IEEE Symposium on Security and Privacy his advanc
 es.  He coauthored a book on Bootstrapping Trust in Modern Computers\, and
  his work in that area has been incorporated into the latest security enha
 ncements in Intel CPUs. His research into security for new application mod
 els was incorporated into Windows and received a Best Paper Awards at the 
 IEEE Symposium on Security and Privacy and the USENIX Symposium on Network
 ed Systems Design and Implementation.  He has recently extended his intere
 st in bootstrapping trust to the problem of building practical\, formally 
 verified secure systems. His other research interests include user authent
 ication\, secure network protocols\, and security in constrained environme
 nts (e.g.\, RFID tags\, sensor networks\, or vehicles).
DTEND:20160310T163000
DTSTART:20160310T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Bryan Parno (Microsoft Research): Fully Verified
  Outsourced Computation
UID:20160310T153000c@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2844
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:TBD
DTEND:20160329T163000
DTSTART:20160329T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium:  TBD (TBD): TBD
UID:20160329T153000@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2855
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:NOTE: This talk will NOT be broadcast live!\nTBD
DTEND:20160331T163000
DTSTART:20160331T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Jonathan Ragan-Kelley (MIT/Stanford): TBD
UID:20160331T153000a@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2858
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:The recent success of machine learning (ML) in both science and
  industry has generated an increasing demand to support ML algorithms at s
 cale. In this talk\, I will discuss strategies to gracefully scale machine
  learning on modern parallel computational platforms. A common approach to
  such scaling is coordination-free parallel algorithms\, where individual 
 processors run independently without communication\, thus maximizing the t
 ime they compute. However\, analyzing the performance of these algorithms 
 can be challenging\, as they often introduce race conditions and synchroni
 zation problems.\n\nIn this talk\, I will introduce a general methodology 
 for analyzing asynchronous parallel algorithms. The key idea is to model t
 he effects of core asynchrony as noise in the algorithmic input.  This all
 ows us to understand the performance of several popular asynchronous machi
 ne learning approaches\, and to determine when asynchrony effects might ov
 erwhelm them.  To overcome these effects\, I will propose a new framework 
 for parallelizing ML algorithms\, where all memory conflicts and race cond
 itions can be completely avoided. I will discuss the implementation of the
 se ideas in practice\, and demonstrate that they outperform the state-of-t
 he-art across a large number of ML tasks on gigabyte-scale data sets.\n\nB
 io\nDimitris Papailiopoulos is a postdoctoral researcher in the Department
  of Electrical Engineering and Computer Sciences at UC Berkeley and a memb
 er of the AMPLab. His research interests span machine learning\, coding th
 eory\, and parallel and distributed algorithms\, with a current focus on c
 oordination-free parallel machine learning\, large-scale data and graph an
 alytics\, and the use of codes to speed up distributed computation. Dimitr
 is completed his Ph.D. in electrical and computer engineering at UT Austin
  in 2014. At Austin he worked under the supervision of Alex Dimakis. In 20
 15\, he received the IEEE Signal Processing Society\, Young Author Best Pa
 per Award.
DTEND:20160405T163000
DTSTART:20160405T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Dimitris Papailiopoulos (University of Texas\, A
 ustin/UC Berkeley): Less Talking\, More Learning: Avoiding Coordination In
  Parallel Machine Learning Algorithms
UID:20160405T153000c@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2860
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:The purpose of obfuscation is to recompile programs in a way th
 at preserves their functionality but otherwise renders their code unintell
 igible. Envisioned by Diffie and Hellman already in the 70's as a means of
  obtaining public-key encryption\, it is known by now that this concept ma
 y have far reaching implications to cryptography and complexity theory. In
  particular\, program obfuscation suggests (often exclusive) solutions to 
 some of the most challenging privacy and security problems in the age of c
 loud computing and social networks.\n\nAt the same time\, program obfuscat
 ion has turned out to be  an evasive goal to achieve\, or to even meaningf
 ully define. For a long time\, solutions have been confined to heuristics\
 , whereas attempts to achieve any sense of provable security have mostly l
 ed to impossibility results. This gloomy state dramatically changed in rec
 ent years\, when it was shown that a relatively weak notion called indisti
 nguishability obfuscation may be within reach (so far\, based on strong co
 mputational assumptions) and still has the potential of realizing many dre
 am applications.\n\nIn this talk\, I will review the different aspects of 
 obfuscation\, including central notions\, limitations\, and feasibility. A
 s a demonstration of the power of obfuscation\, I will present a recent im
 plication [Bitansky-Paneth-Rosen\, FOCS15] that goes beyond cryptography i
 nto a fundamental problem in complexity and algorithmic game theory -- the
  hardness of finding a Nash equilibrium. I will conclude with the main ope
 n problems and challenges in the area of obfuscation.\n\nBio\nNir Bitansky
  is a postdoctoral associate at the cryptography group at MIT CSAIL. He ea
 rned his Ph.D. in computer science from Tel Aviv University in 2014. His r
 esearch is centered around cryptography and its interplay with other areas
  of theoretical computer science.
DTEND:20160407T163000
DTSTART:20160407T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Nir Bitansky (Tel Aviv University/MIT): Program 
 obfuscation: the power of unreadable code
UID:20160407T153000b@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2865
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:Convex optimization has been studied extensively and is a promi
 nent tool in various areas such as combinatorial optimization\, data analy
 sis\, operations research\, and scientific computing.  Each field has deve
 loped specialized tools including data structures\, sampling methods\, and
  dimension reduction. In the past several years\, I have been combining an
 d improving the optimization techniques from different fields to design fa
 ster optimization algorithms. \n  \nIn this talk\, I will discuss my work 
 in this direction and illustrate it through my results on linear programmi
 ng and general convex optimization. In particular\, I will present a new a
 lgorithm for solving linear programs\, which gives the first improvement t
 o the running time for linear programming in 25 years. Then\, I will prese
 nt the first nearly cubic time algorithm for solving general convex optimi
 zation problems. Furthermore\, I will discuss how these two results can be
  used to improve the running time of many classical combinatorial problems
  such as maximum flow and submodular function minimization.\n  \nThis talk
  will assume no prior knowledge of optimization.\n  \nBio: \nYin Tat Lee i
 s a Ph.D. candidate in the department of mathematics at the Massachusetts 
 Institute of Technology. He is interested in designing faster algorithms\,
  particularly for problems in optimization. Since he began his Ph.D. in 20
 12\, he has combined ideas from continuous and discrete mathematics to sub
 stantially advance the state-of-the-art for solving many fundamental probl
 ems in computer science\, such as linear programming\, maximum flow\, and 
 submodular function minimization. He has received a variety of awards\, in
 cluding the Best Student Paper Award at FOCS 2015\, Best Paper Award at SO
 DA 2014\, Best Paper Award and Best Student Paper Award at FOCS 2014\, and
  Notable Article in Computing in 2014 by Computing Reviews.
DTEND:20160412T163000
DTSTART:20160412T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Yin Tat Lee (MIT): Faster algorithms for fundame
 ntal convex problems and their applications in combinatorial optimization
UID:20160412T153000b@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2856
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:The goal of my research is to develop algorithmic and theoretic
 al techniques that push highly agile robotic systems to the brink of their
  hardware limits while guaranteeing that they operate in a safe manner des
 pite uncertainty in the environment and dynamics.\n  \nIn this talk\, I wi
 ll describe my work on algorithms for the synthesis of feedback controller
 s that come with associated formal guarantees on the stability of the robo
 t and show how these controllers and certificates of stability can be used
  for robust planning in environments previously unseen by the system. In o
 rder to make these results possible\, my work connects deeply to computati
 onal tools such as sums-of-squares (SOS) programming and semidefinite prog
 ramming from the theory of mathematical optimization\, along with approach
 es from nonlinear control theory.\n  \nI will describe this work in the co
 ntext of the problem of high-speed unmanned aerial vehicle (UAV) flight th
 rough cluttered environments previously unseen by the robot. In this conte
 xt\, the tools I have developed allow us to guarantee that the robot will 
 fly through its environment in a collision-free manner despite uncertainty
  in the dynamics (e.g.\, wind gusts or modeling errors). The resulting har
 dware demonstrations on a fixed-wing airplane constitute one of the first 
 examples of provably safe and robust control for robotic systems with comp
 lex nonlinear dynamics that need to plan in realtime in environments with 
 complex geometric constraints.\n  \nBio: \nAnirudha Majumdar is a Ph.D. ca
 ndidate in the Electrical Engineering and Computer Science department at M
 IT. He is a member of the Robot Locomotion Group at the Computer Science a
 nd Artificial Intelligence Lab and is advised by Prof. Russ Tedrake. Ani r
 eceived his undergraduate degree in Mechanical Engineering and Mathematics
  from the University of Pennsylvania\, where he was a member of the GRASP 
 lab. His research is primarily in robotics: he works on algorithms for con
 trolling highly dynamics robots such as unmanned aerial vehicles with form
 al guarantees on the safety of the system. Ani's research has been recogni
 zed by the Siebel Foundation Scholarship and the Best Conference Paper Awa
 rd at the International Conference on Robotics and Automation (ICRA) 2013.
 \n
DTEND:20160414T163000
DTSTART:20160414T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Anirudha Majumdar (MIT): Control of agile robots
  in complex environments with formal safety guarantees
UID:20160414T153000a@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2874
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:At present\, user interfaces are typically created by designers
  for an idealized set of users and the most common interactive devices. In
  view of the growing number and diversity of new devices\, it becomes incr
 easingly difficult to design for the many possible input/output characteri
 stics and contexts of use\, and interfaces remain fairly limited in their 
 ability to adapt to devices and their role in a user's larger task. In thi
 s talk\, I will describe how my research in human-computer interaction blu
 rs the boundaries of interactive technologies and enables user interfaces 
 to seamlessly grow\, with the help of users and crowds\, to take advantage
  of many devices and use contexts that are poorly supported by current des
 ign. For example\, W3Touch allows user interfaces to adapt to a large vari
 ety of touch devices based on user performance metrics and crowd data mini
 ng\; XDBrowser customizes existing single-device web interfaces for multi-
 device use based on user-defined cross-device design patterns\; and WearWr
 ite allows a user to provide input and interact with a document using thei
 r smartwatch on one end of the interface\, and a crowd of writers to perfo
 rm actions on the user's behalf using larger and more powerful devices on 
 the other end of the interface. I will outline a research agenda that has 
 the goal of making user interface design itself natural\, embedding human 
 intelligence into interactive computing technologies\, and supporting evid
 ence-based design using large-scale interaction data.\n  \nBio: \nMichael 
 Nebeling is a Swiss NSF Advanced Postdoc.Mobility Fellow and a Visiting Re
 searcher in the Human-Computer Interaction Institute at Carnegie Mellon Un
 iversity hosted by Anind Dey. Before coming to CMU in 2015\, he was a Seni
 or Researcher and Lecturer at the Department of Computer Science at ETH Zu
 rich\, where he obtained his PhD in 2012. His research interests are at th
 e intersection of human-computer interaction\, user interface engineering\
 , ubiquitous computing\, and crowdsourcing. As part of his research\, he h
 as created many systems to support the design and evaluation of rich\, con
 text-aware and adaptive\, cross-device\, multi-touch and multi-modal gestu
 re and speech interfaces\, and has received six Best Paper Awards and Hono
 rable Mentions at premier venues in human-computer interaction and enginee
 ring\, including ACM CHI and ACM EICS. Michael is committed to promoting e
 ngineering research within the HCI community. He has been an Associate Cha
 ir for the CHI Technology\, Systems and Engineering subcommittee for CHI 2
 014-2016. He was EICS 2015 Papers co-chair and EICS 2014 Late-Breaking Res
 ults co-chair. He is on the EICS steering committee and also a Senior PC m
 ember for EICS 2016.\n
DTEND:20160419T163000
DTSTART:20160419T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Michael Nebeling (ETH Zurich/CMU): Multiple Devi
 ces + Crowds = Richer User Interfaces
UID:20160419T153000a@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2863
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:TBD
DTEND:20160421T163000
DTSTART:20160421T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Tony Nowatzki (): TBD
UID:20160421T153000a@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2875
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:TBD
DTEND:20160426T163000
DTSTART:20160426T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Julia Rubin (University of Toronto/MIT): TBD
UID:20160426T153000@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2862
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:When real people interact with algorithms (e.g. in auctions\, c
 rowdsourcing\, Bitcoin\, etc.)\, they impose additional desiderata beyond 
 simply that the algorithm is correct\, fast\, and uses little storage. Peo
 ple strategize during these interactions\, so algorithms deployed in these
  settings must be robust against strategic manipulation. Additionally\, pe
 ople prefer transparent interactions\, so these algorithms must also be as
  simple as possible. My research addresses these\, and other novel challen
 ges that arise when algorithms interact with strategic agents.\n  \nIn thi
 s talk\, I will focus on robustness against strategic manipulation\, and p
 resent a new algorithmic framework for these settings. Specifically\, I wi
 ll present a black-box reduction from solving any optimization problem in 
 strategic settings\, where the input is held by selfish agents with intere
 sts of their own\, to solving a perturbed version of that same optimizatio
 n problem in traditional settings\, where the input is directly given. I w
 ill further apply this framework to resolve two longstanding open problems
 : extending Myerson's celebrated characterization of optimal single-item a
 uctions to multiple items (Myerson 1981)\, and designing truthful mechanis
 ms for job scheduling on unrelated machines (Nisan and Ronen 1999). \n  \n
 Finally\, I will briefly show how strategic considerations motivate nice q
 uestions in "traditional" areas of algorithm design as well\, and present 
 some of my work in convex optimization\, parallel algorithms\, and prophet
  inequalities. \n  \nBio: \nMatt received his PhD in EECS from MIT in 2014
 \, where he was advised by Costis Daskalakis. He is now a postdoc at Princ
 eton University in the Computer Science department. His research focuses o
 n designing algorithms that address constraints imposed by the strategic n
 ature of agents that interact with them. For his thesis work on these topi
 cs\, he received MIT's George M. Sprowls award and the SIGecom Doctoral Di
 ssertation award. Matt received his B.A. in Math from Cornell University.
DTEND:20160428T163000
DTSTART:20160428T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium: Matt Weinberg (MIT/Princeton): Algorithms for St
 rategic Agents
UID:20160428T153000b@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2876
END:VEVENT
BEGIN:VEVENT
DESCRIPTION:TBD
DTEND:20160505T163000
DTSTART:20160505T153000
LOCATION:EEB-105
SUMMARY:UW CSE Colloquium:  TBD (TBD): TBD
UID:20160505T153000@colloquia.cs.washington.edu
URL:http://www.cs.washington.edu/htbin-post/mvis/mvis?ID=2878
END:VEVENT
END:VCALENDAR
