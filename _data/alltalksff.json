{"records": [{"Topic": "Privacy in the land of plenty", "Description": "Privacy-preserving data analysis has a large literature that spans several disciplines. Differential privacy a notion tailored to situations in which data are plentiful -- has provided a theoretically sound and powerful framework, and given rise to an explosion of research. We will review the definition of differential privacy, describe some algorithmic contributions, and conclude with a surprising application.", "Tags": ["Colloquium", "motion", "research", "talk", "effect", "video"]}, {"Topic": "Coordinating $4.1B of federal IT research and development: the NITRD and NCO", "Description": "How does the Federal government set priorities for its research and development programs? How are strategic plans developed? How do the agencies coordinate their efforts? How does Congress keep track of how research funds are spent? In this talk, I will give one view of the answers to these and related questions - the view from a small office under the White House that coordinates $4.1B or Federal IT Research and Development - the NITRD NCQ. You will also learn how to pronounce NITRD NCO.", "Tags": ["Colloquium", "motion", "research", "talk", "effect", "video"]}, {"Topic": "A pit and the pendulum", "Description": "Since the elegant foundations of transaction processing were established in the mid 70 with the notion of serializability and the codification of the ACID (Atomicity, Consistency, Isolation, Durability) paradigm, performance has not been considered one of ACID strong suits, especially for distributed data stores. Indeed, the N0SQL/BASE movement of the last decade was born out of frustration with the limited scalability of traditional ACID solutions, only to become itself a source of frustration once the challenges of programming applications in this new paradigm began to sink in. But how fundamental is this dichotomy between performance and ease of programming? In this talk, I will share what my students and I have recently learned while trying to overcome the traditional terms of this classic tradeoff.", "Tags": ["Colloquium", "motion", "research", "talk", "effect", "video"]}, {"Topic": "A big world of tiny motions", "Description": "We have developed a motion microscope to visualize small motions by synthesizing a video with the desired motions amplified. We initially sought to amplify small color changes in videos, allowing color changes from blood flow to be visualized. Modifications to this algorithm allow small motions to be amplified. I will describe the algorithms, and show color-magnified videos of adults and babies, and motion-magnified videos of throats, pipes, cars, bridges, smoke, and pregnant bellies. The motion microscope lets us see the world of tiny motions, and it may be useful in areas of science and engineering. Having this tool led us to explore other vision problems involving tiny motions. I will describe recent work in analyzing fluid flow and depth by exploiting small motions in video or stereo video sequences caused by refraction of turbulent air flow (joint work with the authors below and Tianfan Xue, Anat Levin, and Hossein Mobahi). We have also developed a visual microphone to record sounds by watching objects, like a bag of chips, vibrate (joint with the authors below and Abe Davis and Gautam Mysore).", "Tags": ["Colloquium", "motion", "research", "talk", "effect", "video"]}, {"Topic": "Beyond worst case analysis for graph partitioning", "Description": "Graph Partitioning problems like Balanced Cut form a central topic of study in computer science. However, good guarantees (e.g. constant factor approximations) have been elusive for many of these problems. Since real-world instances are unlikely to behave like worst-case instances, a compelling question is : can we design better algorithms for real-world instances? In this talk, I will discuss two paradigms that go beyond traditional worst-case analysis: (realistic) average-case analysis, and instance stability. I will use these paradigms to show significantly better guarantees for graph partitioning. In the first part of the talk, I will introduce new average-case models for graph partitioning that are more general that previous models, and that we believe, capture many properties of real-world instances. I will then present a new algorithmic framework based on semidefinite programming that gives constant factor approximation algorithms in these average-case models. In the second part of the talk, I will describe how convex relaxations for certain graph partitioning problems become integral on instances that satisfy a natural notion of stability introduced by Bilu and Linial.", "Tags": ["Colloquium", "motion", "research", "talk", "effect", "video"]}, {"Topic": "Machine learning and econometrics with applications to internet search", "Description": "This talk will provide an overview of recent research combining ideas from machine learning and econometrics, with a focus on estimating causal effects and doing counterfactual policy evaluation in applications with big data, such as internet search. We briefly review a series of papers that cover structural modeling in economics; hypothesis testing in network experiments; robustness of causal estimates using regression tree-based methods; and novel methods for hypothesis-testing when analyzing causal effects. The talk will then go further in depth on a study of the problem of estimating heterogeneity in causal effects in experimental or observational studies and conducting inference about the magnitude of the differences in treatment effects across subsets of the population. In applications, our method provides a data-driven approach to determine which subpopulations have large or small treatment effects and to test hypotheses about the differences in these effects. For experiments, our method allows researchers to identify heterogeneity in treatment effects that was not specified in a pre-analysis plan, without concern about invalidating inference due to multiple testing. New methods for cross-validation in this context are highlighted.", "Tags": ["Colloquium", "motion", "research", "talk", "effect", "video"]}, {"Topic": "Convexity, bayesianism, and the quest towards optimal algorithms", "Description": "In this high level and accessible talk I will describe a recent line of works aimed at trying to understand the intrinsic complexity of computational problems by finding optimal algorithms for large classes of such problems. In particular, I will talk about efforts centered on convex programming as a source for such candidate algorithms. As we will see, a byproduct of this effort is a computational analog of Bayesian probability that is of its own interest.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Synthesis and verification for everyone", "Description": "Synthesis and verification tools are revolutionizing the way we build software. They are helping us create programs that run on energy efficient hardware, that control medical devices, and that automate end-user programming by example. Yet these tools remain difficult to build, requiring months or years of work as well as expertise in many fields, from formal methods to programming languages to software engineering. In this talk, I present an approach to constructing synthesis and verification tools that requires little beyond modern programming skills. The approach is realized in Rosette, a new programming language that was inspired by two simple observations. First, modern programming practice relies heavily on domain-specific languages (DSL5), implemented as libraries or interpreters in general-purpose languages (such as JavaScript, Scala, or Racket). Second, while DSLs are amenable to synthesis and verification by reduction to satisfiability modulo theories (SMT), building a symbolic compiler to perform this reduction is difficult and time-consuming. Rosette simplifies the construction of domain-specific programming tools by eliminating the need for building new symbolic compilers. The programmer simply implements a DSL in Rosette and obtains a symbolic compiler for free. This is made possible by Rosette Symbolic Virtual Machine, which can efficiently reduce both a DSL implementation and a program in that DSL to logic. Rosette has been used to develop many DSLs with programming tools that scale to real applications, from synthesis of energy-efficient code for an ultra low-power chip to verification of control software for a radiotherapy machine.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Instruction sets want to be free: a case for RISC-V", "Description": "We start by quickly reviewing 50 years of computer architecture to show there is now widespread agreement on instruction set architecture (ISA). Unlike most other fields, despite this harmony there is no open alternative to proprietary offerings from ARM and Intel. Thus, we propose RISC-V (RISC Five), which targets Systems on a Chip (SoC). It has: A small base of <50 classic RISC instructions that run a full open-source software stack. Opcodes reserved for tailoring an SoC to applications. Standard instruction extensions optionally included in an SoC. Incorporated, as an open ISA, community suggestions before extensions are finalized. A foundation to evolve the RISC-V slowly based solely on technical reasons voted on by members vs. by companies that inflate ISAs rapidly for business as well as technical reasons; ARM and Intel average about 2 new instructions per month. No restrictions: there is no cost, no paperwork, and anyone can use it. Attendees will get a 2-page reference card (green card, which lists all RISC-V extensions, to contrast this minimal ISA with the 3,600-page x86 manual and the 5,400-page ARMv8 manual. We conclude by recapping 10 RISC-V chips built using Agile methods in just 4 years, including how shockingly cheap it is today to manufacture 100 2x2-mm, 28-nm chips. We used Chisel, a new hardware design language that reduces design effort by greatly increasing reuse.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Using formal methods to eliminate exploitable bugs", "Description": "For decades, formal methods have offered the promise of software that does not have exploitable bugs. Until recently, however, it has not been possible to verify software of sufficient complexity to be useful. Recently, that situation has changed. SeL4 is an open-source operating system microkernel efficient enough to be used in a wide range of practical applications. It has been proven to be fully functionally correct, ensuring the absence of buffer overflows, null pointer exceptions, use-after-free errors, etc., and to enforce integrity and confidentiality properties. The Comp Cert Verifying C Compiler maps source C programs to provably equivalent assembly language, ensuring the absence of exploitable bugs in the compiler. A number of factors have enabled this revolution the formal methods community, including increased processor speed, better infrastructure like the Isabelle/HOL and Coq theorem provers, specialized logics for reasoning about low-level code, increasing levels of automation afforded by tactic languages and SAT/SMT solvers, and the decision to move away from trying to verify existing artifacts and instead focus on co-developing the code and the correctness proof. In this talk I will explore the promise and limitations of current formal methods techniques for producing useful software that provably does not contain exploitable bugs. I will discuss these issues in the context of DARPA HACMS program, which has as its goal the creation of high-assurance software for vehicles, including quad-copters, helicopters, and automobiles.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "From robots to biomolecules: computing meets the physical world", "Description": "Over the last decade, the development of fast and reliable motion plan-fling algorithms has deeply influenced many domains in robotics, such as industrial automation and autonomous exploration. Motion planning has also contributed to great advances in an array of unlikely fields, including graphics animation and computational structural biology. This talk will first describe how sampling-based methods revolutionized motion planning in robotics. The presentation will quickly focus on recent algorithms that are particularly suitable for systems with complex dynamics. The talk will then introduce an integrative framework that allows the synthesis of motion plans from high-level specifications. The framework uses temporal logic and formal methods and establishes a tight link between classical motion planning in robotics and task planning in artificial intelligence. Although research initially began in the realm of robotics, the experience gained has led to algorithmic advances for analyzing the motion and function of proteins, the worker molecules of all cells. This talk will conclude by discussing robotics-inspired methods for computing the flexibility of proteins and large macromolecular complexes with the ultimate goals of deciphering molecular function and aiding the discovery of new therapeutics.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Greed in service of tensors for dependency parsing", "Description": "Syntactic parsing is among a few NLP tasks where the problem is hard, yet evaluation is clear. As a result, it has been a battleground for algorithmic innovations in the field. In this talk, I will present ideas behind RBG dependency parser developed at MIT. This parser achieves top performance on several multilingual benchmarks, and was particularly successful on morphologically rich languages. First, I will talk about learning low-dimensional feature representations customized for dependency parsing. Our method explicitly maintains parsing parameters as a low-rank tensor, and leverages modularity in the tensor for easy training with on-line algorithms. Next, I will introduce a simple randomized greedy algorithm that suffices for nearly optimal parsing. The success of the algorithm is tied to the number of local optima in the parsing space. The randomized greedy algorithm with up to third order and global features outperforms the state-of-the-art dual decomposition and MCMC sampling methods.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Learning deep latent features for model predictive control", "Description": "Designing controllers for tasks with complex non-linear dynamics is extremely challenging, time-consuming, and in many cases, infeasible. This difficulty is exacerbated in tasks such as robotic food-cutting, in which dynamics might vary both with environmental properties, such as material and tool class, and with time while acting. In this work, we present DeepMPC, an online real-time model-predictive control approach designed to handle such difficult tasks. Rather than hand-design a dynamics model for the task, our approach uses a novel deep architecture and learning algorithm, learning controllers for complex tasks directly from data. We validate our method in experiments on a large-scale dataset of 1488 material cuts for 20 diverse classes, and in 450 real-world robotic experiments, demonstrating significant improvement over several other approaches.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Thinking on your feet: reinforcement learning for incremental language tasks", "Description": "In this talk, I'll discuss two real-world language applications that require thinking on your feet: synchronous machine translation (or machine simultaneous interpretation) and question answering (when questions are revealed one piece at a time).  In both cases, effective algorithms for these tasks must interrupt the input stream and decide when to provide output. Synchronous machine translation is when a sentence is being produced one word at a time in a foreign language and we want to produce a translation in English simultaneously (i.e., with as little delay between a foreign language word and its English translation). This is particularly difficult in verb-final languages like German or Japanese, where an English translation can barely begin until the verb is seen. Effective translation thus requires predictions of unseen elements of the sentence (e.g., the main verb in German and Japanese, or relative clauses in Japanese, or post-positions in Japanese). We use reinforcement learning to decide when to trust our verb predictions. It must learn to balance incorrect translation versus timely translations, and must use those predictions to translate the sentence. For question answering, we use a specially designed dataset that challenges humans: a trivia game called quiz bowl. These questions are written so that they can be interrupted by someone who knows more about the answer; that is, harder clues are at the start of the question and easier clues are at the end of the question. We create a recursive neural network to predict answers from incomplete questions and use reinforcement learning to decide when to guess.  We are able to answer questions earlier in the questions than most college trivia contestants.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Duolingo: improving language education with data", "Description": "Duolingo is a free online education service that allows people to learn new languages. Since launching three years ago, Duolingo has grown to more than 100 million students from all over the world, and our mobile apps were awarded top honors from both Apple and Google in 2013. In this talk, I will discuss our architecture and present some examples of how we use a data-driven approach to improve the system, drawing on various disciplines including psychometrics, natural language processing, and machine learning.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Online boosting algorithms", "Description": "We initiate the study of boosting in the online setting, where the task is to convert a weak online learner into a strong online learner. The notions of weak and strong online learners directly generalize the corresponding notions from standard batch boosting. For the classification setting, we develop two online boosting algorithms. The first algorithm is an online version of boost-by-majority, and we prove that it is essentially optimal in terms of the number of weak learners and the sample complexity needed to achieve a specified accuracy. The second algorithm is adaptive and parameter-free, albeit not optimal. For the regression setting, we give an online gradient boosting algorithm which converts a weak online learning algorithm for a base class of regressors into a strong online learning algorithm which works for the linear span of the base class. We also give a simpler boosting algorithm for regression that obtains a strong online learning algorithm which works for the convex hull of the base class, and prove its optimality.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Broad-coverage CCG semantic parsing with AMR", "Description": "Semantic parsing, the task of mapping sentences to logical form meaning representations, has recently received significant attention. We propose a grammar induction technique for AMR semantic parsing. While previous grammar induction techniques were designed to re-learn a new parser for each target application, the recently annotated AMR Bank provides a unique opportunity to induce a single model for understanding broad-coverage newswire text and support a wide range of applications. We present a new model that combines CCG parsing to recover compositional aspects of meaning and a factor graph to model non-compositional phenomena, such as anaphoric dependencies. Our approach achieves 66.2 Smatch F1 score on the AMR bank, significantly outperforming the previous state of the art. This talk is an extended version of our EMNLP 2015 talk.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Efficient and parsimonious agnostic active learning", "Description": "We develop a new active learning algorithm for the streaming setting satisfying three important properties: 1) It provably works for any classifier representation and classification problem including those with severe noise. 2) It is efficiently implementable with an ERM oracle. 3) It is more aggressive than all previous approaches satisfying 1 and 2. To do this we create an algorithm based on a newly defined optimization problem and analyze it. We also conduct the first experimental analysis of all efficient agnostic active learning algorithms, evaluating their strengths and weaknesses in different settings.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Approximate lifted inference with probabilistic databases", "Description": "Probabilistic inference over large data sets is becoming a central data management problem. Recent large knowledge bases, such as Yago, Nell or DeepDive have millions to billions of uncertain tuples. Yet probabilistic inference is known to be NP-hard in the size of the database, even for some very simple queries. This talk shows a new approach that allows ranking answers to hard probabilistic queries in guaranteed polynomial time, and by using only basic operators of existing database management systems (e.g., no sampling required). (1) The first part of this talk develops upper and lower bounds for the probability of Boolean functions by treating multiple occurrences of variables as independent and assigning them new individual probabilities. We call this approach dissociation and give an exact characterization of optimal oblivious bounds, i.e. when the new probabilities are chosen independent of the probabilities of all other variables. Our new bounds shed light on the connection between previous relaxation-based and model-based approximations and unify them as concrete choices in a larger design space. (2) The second part then draws the connection to lifted inference and shows how application of this theory allows a standard relational database management system to both upper and lower bound hard probabilistic queries in guaranteed polynomial time. We give experimental evidence on synthetic TPC-H data that our approach is by orders of magnitude faster and also more accurate than currently used sampling-based approaches. ", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Decoding the brain to help build machines", "Description": "Humans can describe observations and act upon instructions.  This requires that language be grounded in perception and motor control.  I will present several components of my long-term research program to understand the vision-language-motor interface in the human brain and emulate such on computers. In the first half of the talk, I will present fMRI investigation of the vision-language interface in the human brain.  Subjects were presented with stimuli in different modalities,---spoken sentences, textual presentation of sentences, and video clips depicting activity that can be described by sentences---while undergoing fMRI.  The scan data is analyzed to allow readout of individual constituent concepts and words---people/names, objects/nouns, actions/verbs, and spatial-relations/prepositions---as well as phrases and entire sentences.  This can be done across subjects and across modality; we use classifiers trained on scan data for one subject to read out from another subject and use classifiers trained on scan data for one modality, say text, to read out from scans of another modality, say video or speech.  Analysis of this indicates that the brain regions involved in processing the different kinds of constituents are largely disjoint but also largely shared across subjects and modality.  Further, we can determine the predication relations; when the stimuli depict multiple people, objects, and actions, we can read out which people are performing which actions with which objects.  This points to a compositional mental semantic representation common across subjects and modalities. In the second half of the talk, I will use this work to motivate the development of three computational systems.  First, I will present a system that can search a collection of ten full-length Hollywood movies for clips that depict actions specified in sentential queries.  This is done without any annotation or markup of the video.  Second, I will present a system that can use sentential description of human interaction with previously unseen objects in video to automatically find and track those objects.  This is done without any annotation of the objects and without any pretrained object detectors. Third, I will present a system that learns the meanings of nouns and prepositions from video and tracks of a mobile robot navigating through its environment paired with sentential descriptions of such activity.  Such a learned language model then supports both generation of sentential description of new paths driven in new environments as well as automatic driving of paths to satisfy navigational instructions specified with new sentences in new environments.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Non-convex gradient descent for fitting low-rank models", "Description": "Fitting a structured rank-r matrix to noisy data is an important subroutine in many applications (PCA, clustering, collaborative filtering) It involves solving a (NP-hard) rank-constrained optimization problem. Popular approach via convex relaxation runs in polynomial time in principle and has strong statistical guarantees, but its quadratic time complexity is often too high for large problems. An attractive and highly scalable alternative is to run (projected) gradient descent directly over the space of low-rank matrices, but convergence and statistical accuracy were unclear due to non-convexity. We develop a unified framework characterizing the convergence of this non-convex method as well as the statistical properties of the resulting solution. Our results provide convergence guarantees for a broad range of low-rank problems in machine learning and statistics, including matrix sensing, matrix completion with real and one-bit observations, matrix decomposition, robust and structured PCA, graph clustering, and others. For these problems non-convex projected gradient descent runs in near linear time, and provides statistical guarantees that match (and sometimes better than) the best known results.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Low-rank spectral learning", "Description": "Modern machine learning can often be characterized as the application of optimization techniques to loss objectives.  This approach has clear intuitions, generalization guarantees, and a track record of empirical success.  However, optimization can be computationally expensive, and often there is no guarantee of finding the global optimum. As a result, there has been a growing interest in alternative \"method of moments\" algorithms, including spectral learning and tensor decomposition methods, that attempt to recover model parameters directly by manipulating statistics of the training set.  Hsu, Kakade, and Zhang, for example, showed that their seminal spectral learning algorithm can learn hidden Markov models (HMMs) quickly, exactly, and in closed form, in stark contrast to EM. However, the assumptions of Hsu et al are unrealistic: they require that the training data are generated by an HMM whose number of states (rank) exactly matches the model being learned.  In the real world, this is virtually never true.  Empirical data are noisy and complex, and for computational and statistical reasons we usually want to fit a low-rank model.  As a result, during spectral learning we typically throw out the smallest singular values of the statistics matrix. Intuitively, this seems like a reasonable approximation. However, I will describe a surprising result: even when the singular values thrown out are arbitrarily small, the resulting prediction errors can be arbitrarily large.  I will identify two distinct causes for this bad behavior, illustrate them with simple examples, and prove that they are essentially complete: if neither occurs, the prediction error is bounded by the magnitudes of the omitted singular values. Finally, I will describe a limiting case in which we can prove that this problem disappears entirely.  By studying the properties of this limiting case we can derive several conceptual and practical insights that lead to improved empirical performance on both synthetic and real-world problems, as well as pave the way toward a theoretical understanding of spectral learning under realistic assumptions.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Model reduction for edge-weighted personalized pagerank", "Description": "In this talk, I will describe work on model reduction for fast computation of PageRank for graphs in which the edge weights depend on parameters. For an example learning-to-rank application, our approach is nearly five orders of magnitude faster than the standard approach. This speed improvement enables interactive computation of a class of ranking results that previously could only be computed offline. While our approach draws on ideas common in model reduction for large physical simulations, the cost and accuracy tradeoffs for the edge-weighted PageRank problem are different, as we will describe.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Nonlinear multigrid for scalable power grid simulations", "Description": "A key tool for power grid operators in ensuring reliable operation is the simulation of the power grid under possible contingency conditions. Central to these simulations are the power flow equations, a set of complex quadratic equations whose solution provides the voltage levels around the network. Modern power flow solvers typically use some variation of Newton's method, which is efficient for small to medium sized problems. However, the advent of the smart grid has brought with it a desire for increasingly detailed simulations. As problem sizes grow correspondingly larger, Newton's method appears less attractive. Multigrid methods are a set of recursive techniques for solving linear systems that turn cheap, parallelizable methods such as the Jacobi iteration into highly effective solvers for large problems. In this talk, I will extend the multigrid framework to complex quadratic problems, and show how to use it to solve the power flow problem in a highly parallel manner. While this research is ongoing, initial experiments indicate that it scales favorably with problem size, making it a potentially useful approach for large-scale simulations.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Anisotropic models of pedestrian crowds", "Description": "In this talk, I will describe models of the movement of pedestrian crowds based on a framework developed by R.L. Hughes (A continuum theory for the flow of pedestrians, 2002). Anisotropy in these models can come from two main sources: inter-crowd and intra-crowd interactions. I will explain why anisotropic interactions result in potential difficulties for the consistency and stability of these models. I will also discuss numerical simulations for the corresponding system of PDEs based on a locking sweeping approach.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Vectorization and parallelization of track reconstruction codes for the large hadron collider", "Description": "Track finding and fitting is one of the most computationally challenging problems for event reconstruction in particle physics. At CERN, for example, it will become by far the dominant problem in the upcoming high luminosity era of the Large Hadron Collider (LHC). Massively parallel processing will be essential due to the extremely high event rate of the HL-LHC. In an effort to expand parallelism, various track finding techniques have been explored, but the most common ones in use today are those based on the Kalman Filter. Significant experience has been accumulated with Kalman Filter techniques in real tracking detector systems; they are known to provide high physics performance, are robust, and are in fact the very ones that have been used in the design of the tracking system for HL-LHC. Kalman Filter methods have already been parallelized on a large-grain, per-event basis. However, modern CPU design has been pushing the available parallelism down to much finer-grain scales, due mainly to power density constraints. While processor features continue to shrink in size in accordance with Moore's Law, not all existing code implementations will see the benefit. In order to realize the expected performance/price gains, it will be necessary for algorithms to exploit larger numbers of lightweight cores, together with specialized functional units such as extra-wide vector units. Examples of these lower-power, multi-core processor technologies today include Intel's Xeon Phi and GPGPUs. In our current investigation, we parallelize the usual Kalman Filter algorithm per track, rather than per event. We find that by grouping multiple tracks into a carefully optimized data structure, and processing them simultaneously within the vector unit associated with a single thread, Kalman-Filter-based track fitting can achieve large speedups both with Intel Xeon and Xeon Phi. We report on some of our progress towards an end-to-end track reconstruction algorithm fully exploiting vectorization and parallelization techniques in a realistic simulation setup.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Generating effective kinetic biochemical models from natural language descriptions", "Description": "Current strategies for biochemical model generation and interrogation rely on standards-based XML model specifications, such as the Systems Biology Markup Language (SBML), to represent the underlying biology and some aspects of the simulations used to interrogate the model. However, these approaches often lock users into specific software applications, are not well designed from a usability perspective, are often lacking in standards support, and require expert domain specific knowledge typically missing in biologists or clinicians. We have taken a different approach; we will present a new framework being developed in our lab at Cornell University for generating course grained effective kinetic models of gene expression and metabolic processes in prokaryotes from natural language. We will present a prototype system, written in the Swift programming language, and use this system to generate, and subsequently analyze example models, including a model of carbon catabolite repression in Bacillus subtilis.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "On-line stability assessment of practical power grids: methods, nonlinear computations and field installations", "Description": "For many utilities around the world, there has been considerable pressure to increase power flows over existing transmission corridors. This consistent pressure has prompted the requirement for extending current energy management systems (EMS) to perform on-line transient stability assessment (TSA) and control. Such extension, however, is a rather difficult task and requires several break-throughs in analysis tools, computation methods and control schemes. Indeed, on-line TSA, concerned with power system stability/instability after contingencies, requires the handling of a large set of nonlinear differential equations in addition to the nonlinear algebraic equations involved in the static security assessment. TSA is designed to provide power system operators with critical information including, (i) transient stability subject to a list of contingencies and (ii) available (power) transfer limits at key interfaces subject to transient stability constraints. The PJM Interconnection, one of the largest utility in the world, has successfully designed and implemented a TSA system. TEPCO-BCU was selected as the leading fast screening tool for improving the performance of the PJM TSA system. This talk will cover mathematical problem formulation, theoretical foundation, and the BCU method and demonstrate one practical application of the theory-based BCU method on the PJM interconnection system, a 14,000-bus power system dynamic model with a list of 3000 contingencies, with practical data in an on-line environment. This confirms the author belief that theory-based solution methods can lead to practical applications in large-scale nonlinear systems such as power systems.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Feasibility of navigating a one-meter sailboat on the oceans for month", "Description": "Can a one meter sailboat survive on the world oceans for years without human contact? The boat is slow and winds and currents can be large. So, simultaneously being pushed by and using the variety of changing winds and currents, can such a boat survive without crashing. We partially address this question using the controls concept of reachability. For given current, and wind at a given location a given boat at that place has a set of speeds it can travel, one speed for each candidate direction. For example, if the boat is slow and the current large the possible net velocities are all close to the water current velocity. The oceans can be divided into regions: 1) regions where the boat can hold position; 2) regions where a boat can revisit any point in that region any number of times; 3) regions with one way passage between regions (2); 4) regions where survival is possible, but points cannot be revisited; 5) regions where crashes are inevitable. We develop and apply viability and reachability methods to investigate these regions using real ocean current data. The key result is that the surviving regions 1-4 can be substantial even if the boat speed is much less than the maximum water current. The various regions generalize familiar concepts from 2D dynamical systems theory (stable and unstable fixed points, limit cycles, etc). This talk will cover the motivation for this work (environmental monitoring) and the problem formulation. Computation methods will be discussed and initial results towards answering the question at hand will be shown.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Integrating uncertain renewables in power systems: leveraging flexibility in operational models", "Description": "The steady increase of electricity demand and the use of uncertain renewable energy sources requires improvement in the ability of power systems to adapt to changes in supply and demand. The first step in this evolution is the adaptation of planning and operational models to account for uncertainty on both the demand and supply side of the system. An additional challenge is the fact that power systems are very complex systems, with uncertainties that do not fit nicely into distributional paradigms. In this presentation a data-driven stochastic optimization model will be presented that uses a chance-constrained formulation to manage uncertainty in a manner that is customizable and scalable. Preliminary results will explore potential scalability and compare the chance-constrained approach with robust methods.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Investigating complex chemical systems: classical trajectories for quantum processes", "Description": "Addressing the challenge of controlling charge and energy transfer in complex material systems requires theoretical methods that accurately described the coupling between electronic state transitions and nuclear dynamics, and that are computationally efficient for complex many-dimensional systems. In this talk, we introduce two recent approximate dynamic techniques developed in our group that leverage the computational efficiency of classical mechanics while incorporating quantum effects. We demonstrate the numerical accuracy of these methods in model systems and we discuss the challenges associated with extending their implementation to atomistic simulations of chemical reactions.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "A numerical study of cluster-induced turbulence using a volume-filtered Euler-Lagrange approach", "Description": "Disperse particle-laden flows are common in many environmental and industrial applications, and are often turbulent. Some examples include liquid-solid slurry pipelines, underwater sediment transport, fuel spray injection, and fluidized bed reactors. Due to the intricate coupling between granular mechanics and turbulence, understanding and modeling such flows present a significant challenge. In this talk, we will first present a computational framework for conducting highly resolved Euler-Lagrange simulations based on explicit volume filtering. We will show that this framework is appropriate to use in both dilute and dense particle-laden flows by comparing simulation results to available experimental data for a wide variety of flow conditions. We will then turn our attention to particle clustering by focusing on flows where a strong coupling between the phases leads to spontaneous generation of concentration inhomogeneity. Sustained concentration and velocity fluctuations caused by the clusters result in the production of fluid-phase turbulent kinetic energy, referred to as cluster-induced turbulence (CIT). A canonical flow configuration for studying CIT will be presented, followed by an analysis of the fluid-particle dynamics. In particular, we will show that by using a well-designed adaptive filter, it is possible to accurately decompose the total fluctuating energy of the particle phase into correlated and uncorrelated components, which correspond, respectively, to the particle-phase turbulent kinetic energy and the mean granular temperature, allowing us to show for example that the granular pressure is highly anisotropic.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "New directions for random walk on a graph", "Description": "Random walk on a graph is a beautiful and (viewed from today) classical subject with elegant theorems, multiple applications in the theory of computing, and a close connection to the theory of electrical networks. The subject seems to be livelier now than ever, with a surprising number of new results. We will discuss recent progress in some new directions. In particular, how long can it take to visit every edge of a graph, or to visit every vertex a representative number of times? Can random walks be coupled so that they don't collide? Can moving targets be harder to hit than fixed targets? How long does it take to capture a random walker?", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Online network design algorithms via hierarchical decompositions", "Description": "I will present a new approach for network design, and apply it to obtain the best possible (up to constants) competitive ratios for several online problems. At the heart of this work is an analysis framework based on embeddings into hierarchically well-separated trees (HSTs). Our approach yields simple greedy algorithms and straightforward analyses. Unlike the usual algorithmic application of tree embeddings, the embeddings are used only for the analysis, not in the algorithms.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "The price of anarchy in large games", "Description": "Game-theoretic models relevant for computer science applications usually feature a large number of players with predictable structural properties. The goal of this talk is to develop an analytical framework for bounding the price of anarchy in such models. Our framework is based on a novel extension of smoothness, a standard technique for developing price-of-anarchy bounds in fixed games, to a sequence of games. We first define an approximate utility -- one that a delusional player might imagine he faces. We prove that this utility well-approximates the actual utility under realistic structural assumptions regarding market size and noise. We then show that this approximate utility is smooth with respect to the actual game. We demonstrate the wide applicability of our framework through instantiations for several well-studied models, including simultaneous single-item auctions, greedy combinatorial auctions, and routing games. In all cases, we identify conditions under which the POA of large games is much better than that of worst-case instances. Our results also give new senses in which simple auctions can perform almost as well as optimal ones in realistic settings.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Near feasible stable matchings with complementarities", "Description": "The National Resident Matching program strives for a stable matching of medical students to teaching hospitals. With the presence of couples, stable matchings need not exist. For any student preferences, we show that each instance of a stable matching problem has a \"nearby\" instance with a stable matching. The nearby instance is obtained by perturbing the capacities of the hospitals. Our approach is general and applies to other type of complementarities, as well as matchings with side constraints and contracts.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Epidemics and the metric dimension", "Description": "Motivated by the problem of detecting the source of an epidemic, we revisit the classic metric dimension problem. The metric dimension of a graph, introduced by Erdos and Renyi, is the minimum size subset of vertices such that all vertices in the graph are uniquely determined by the vector of distances to those in the subset. Interest in this problem arose due to its application to problems such as network verification, navigation, and image digitization, and numerous hardness and algorithmic results have been produced. In this talk I will first show how the metric dimension problem also arises naturally when one is interested in detecting the source of an epidemic. Subsequently, I will present an optimal approximation algorithm for the metric dimension problem.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Near optimal LP rounding for correlation clustering on complete graphs", "Description": "Introduced about 10 years ago by Bansal, Blum and Chawla, correlation clustering has become one of the standard techniques in machine learning and data mining. This due to several advantages of correlation clustering as compared to other standard clustering methods (e.g. k-means): Correlation clustering only requires qualitative information about similarities between objects. This makes it applicable in scenarios such as crowdsourced duplicate finding when information about similarities between objects is generated by humans. Correlation clustering doesn't require the number of clusters to be specified in advance, producing the number of clusters that best fits the data. We give new rounding schemes for the standard linear programming relaxation of the correlation clustering problem, achieving approximation factors almost matching the integrality gaps: For complete graphs our approximation is 2.06 - epsilon for a fixed constant epsilon, which almost matches the previously known integrality gap of 2. For complete k-partite graphs our approximation is 3. We also show a matching integrality gap. For complete graphs with edge weights satisfying triangle inequalities and probability constraints, our approximation is 1.5, and we show an integrality gap of 1.2. Our results improve a long line of work on approximation algorithms for correlation clustering in complete graphs, previously culminating in a ratio of 2.5 for the complete case by Ailon, Charikar and Newman (JACM08). In the weighted complete case satisfying triangle inequalities and probability constraints, the same authors give a 2-approximation; for the bipartite case, Ailon, Avigdor-Elgrabli, Liberty and van Zuylen give a 4-approximation (SICOMP12).", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "An experimental evaluation of the best-of-many christofides algorithm for the traveling salesman problem", "Description": "Recent papers on approximation algorithms for the traveling salesman problem (TSP) have given a new variant on the well-known Christofides algorithm for the TSP, called the Best-of-Many Christofides algorithm. The algorithm involves sampling a spanning tree from the solution the standard LP relaxation of the TSP, subject to the condition that each edge is sampled with probability at most its value in the LP relaxation. One then runs Christofides algorithm on the tree by computing a minimum-cost matching on the odd-degree vertices in the tree, and shortcutting the resulting Eulerian graph to a tour. In this paper we perform an experimental evaluation of the Best-of-Many Christofide' algorithm to see if there are empirical reasons to believe its performance is better than that of Christofides algorithm. Furthermore, several different sampling schemes have been proposed; we implement several different schemes to determine which ones might be the most promising for obtaining improved performance guarantees over that of Christofides algorithm. In our experiments, all of the implemented methods perform significantly better than the Christofides algorithm; an algorithm that samples from a maximum entropy distribution over spanning trees seems to be particularly good, though there are others that perform almost as well.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}, {"Topic": "Tight lower bounds for planted clique in the degree-4 sum-of-squares program", "Description": "The planted clique problem asks us to find a small clique which has been hidden in a random graph. Quasi-polynomial time algorithms are known for hidden cliques of any size, and no polynomial-time algorithm is known for cliques of size less than sqrt(n). Despite this intriguingly vast gap, the problem has evaded algorithmic progress for decades. In this talk I will deliver some bad news, showing that the sum-of-squares relaxation cannot find cliques of size less than sqrt(n) at degree 4.", "Tags": ["Seminar", "algorithm", "use", "system", "problem", "model"]}]}